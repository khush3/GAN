{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cycle_GAN_cuda.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "xl5OfuXwc3vX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Cyclic-GAN\n",
        "# X - paintings and Y - photographs \n",
        "# Y' = F(x)\n",
        "# X' = G(X)\n",
        "\n",
        "batch_size = int(1)\n",
        "displaly_size = int(10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o3z7pTpugiix",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Install the necessary dependencies\n",
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "!pip install Pillow==4.0.0\n",
        "!pip install PIL\n",
        "!pip install image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uTvzIvoQCPKH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Check for cuda\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4uVIhUkBcdTJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Mount drive\n",
        "##To load dataset from Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#Check if drive is mounted\n",
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4l1kOSP6t8xK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io, transform\n",
        "\n",
        "\n",
        "class monet_dataset(Dataset):\n",
        "    \"\"\"Monet dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, path_X, path_Y, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            path_X (string): Path to the X images directory.\n",
        "            path_Y (string): Path to the Y images directory.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.Ximages_path = path_X\n",
        "        self.Yimages_path = path_Y\n",
        "        self.transform = transform\n",
        "        self.list_X =  os.listdir(path_X)\n",
        "        self.list_Y = os.listdir(path_Y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.list_X),len(self.list_Y))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name_X = os.path.join(self.Ximages_path,\n",
        "                                self.list_X[idx%len(self.list_X)])\n",
        "        imageY = io.imread(img_name_X)\n",
        "        img_name_Y = os.path.join(self.Yimages_path,\n",
        "                                self.list_Y[idx%len(self.list_Y)])\n",
        "        imageX = io.imread(img_name_Y)\n",
        "        \n",
        "        if self.transform:\n",
        "            imageX = self.transform(imageX)\n",
        "            imageY = self.transform(imageY)\n",
        "        \n",
        "        return imageX,imageY"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GbgkW_XLB28_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, datasets\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        " #       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        " #       transforms.RandomSizedCrop(224),\n",
        " #       transforms.RandomHorizontalFlip(),\n",
        " #       transforms.ToTensor(),\n",
        " #       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        " #                         std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "# Create datasets\n",
        "trainset = dataset('/content/drive/My Drive/Projects/monet2photo/trainA/TrainA','/content/drive/My Drive/Projects/monet2photo/trainB/TrainB', data_transform)\n",
        "test_set = dataset('/content/drive/My Drive/Projects/monet2photo/testA/TestA','/content/drive/My Drive/Projects/monet2photo/testB/TestB', data_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GMLb6FbvCBqQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img.cpu()\n",
        "    npimg = img.detach().numpy()\n",
        "    plt.imshow(torchvision.utils.make_grid(np.transpose(npimg, (1, 2, 0))))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iJcyhpbxdHxd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Discriminator model \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        \n",
        "        super(Discriminator, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size = 4, stride= 2),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, kernel_size = 4, stride= 2),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 256, kernel_size = 4, stride= 2),\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(256, 512, kernel_size = 4, stride= 2),\n",
        "            nn.InstanceNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(512, 1, kernel_size = 14, stride= 1),  #Apply conv to get one dimensional output\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "        x = self.block(x);\n",
        "        return x   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WUC0NPpgdOw4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Generator model \n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        \n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        \n",
        "        ## input > ENCODER > RESNET nine times > DECODER > output\n",
        "        \n",
        "        self.encode = nn.Sequential(\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(3, 64, kernel_size = (7), stride= 1, padding = 2),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size = (3), stride= 2, padding = 0),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size = (3), stride= 2, padding = 1),\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        \n",
        "        self.resnet = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size = (1), stride= 1),\n",
        "            nn.BatchNorm2d(256),            \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size = (3), stride= 1, padding=1),\n",
        "            nn.BatchNorm2d(256),            \n",
        "        )\n",
        "        \n",
        "        self.decode = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels = 256, out_channels = 128, kernel_size = 3, stride= 2),      \n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels = 128, out_channels = 64, kernel_size = 2, stride= 2),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 3, kernel_size = (7), stride= 1),\n",
        "            nn.InstanceNorm2d(3),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.encode(x);\n",
        "        x = F.relu(x + self.resnet(x));\n",
        "        x = F.relu(x + self.resnet(x));\n",
        "        x = F.relu(x + self.resnet(x));\n",
        "        x = F.relu(x + self.resnet(x));\n",
        "        x = F.relu(x + self.resnet(x));\n",
        "        x = F.relu(x + self.resnet(x));\n",
        "        x = F.relu(x + self.resnet(x));\n",
        "        x = F.relu(x + self.resnet(x));\n",
        "        x = F.relu(x + self.resnet(x));\n",
        "        x = self.decode(x);\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HJFZ-Ss3dQo9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create an instances of the generator and discriminator\n",
        "\n",
        "F_gen = Generator()\n",
        "F_dis = Discriminator()\n",
        "F_gen = F_gen.cuda()\n",
        "F_dis = F_dis.cuda()\n",
        "\n",
        "G_gen = Generator()\n",
        "G_dis = Discriminator()\n",
        "G_gen = G_gen.cuda()\n",
        "G_dis = G_dis.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "poFFd5CyfgzN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "real_images_Y = torch.randn(batch_size,3,256,256)\n",
        "real_images_X = torch.randn(batch_size,3,256,256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RPDoOH0DdWPT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create optimization function and loss function for both generator and discriminator\n",
        "import torch.optim as optim\n",
        "\n",
        "criteriondis = nn.MSELoss()\n",
        "criterion_feature = nn.L1Loss()\n",
        "F_gen_optimizer = optim.Adam(F_gen.parameters(), lr=0.0002, betas = (0.5,0.999))\n",
        "F_dis_optimizer = optim.Adam(F_dis.parameters(), lr = 0.0002, betas = (0.5,0.999))\n",
        "G_gen_optimizer = optim.Adam(G_gen.parameters(), lr=0.0002, betas = (0.5,0.999))\n",
        "G_dis_optimizer = optim.Adam(G_dis.parameters(), lr = 0.0002, betas = (0.5,0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wtNQVd26dato",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Train the C-GAN\n",
        "for epoch in range(2):\n",
        "\n",
        "    F_running_loss_real = 0.0\n",
        "    F_running_loss_fake = 0.0\n",
        "    F_running_loss_gen  = 0.0\n",
        "    G_running_loss_real = 0.0\n",
        "    G_running_loss_fake = 0.0\n",
        "    G_running_loss_gen  = 0.0\n",
        "    F_running_cyclic_loss = 0.0\n",
        "    G_running_cyclic_loss = 0.0        \n",
        "    \n",
        "\n",
        "    for i in range(len(trainset)):\n",
        "        \n",
        "        # get the inputs \n",
        "        real_images_X[0], real_images_Y[0] = trainset[i]\n",
        "        real_images_X = real_images_X.cuda()\n",
        "        real_images_Y = real_images_Y.cuda()\n",
        "        ones = torch.ones((batch_size,1,1,1))\n",
        "        zeros = torch.zeros((batch_size,1,1,1))\n",
        "        ones = ones.cuda()\n",
        "        zeros = zeros.cuda()\n",
        "\n",
        "        #F\n",
        "        # zero the parameter gradients\n",
        "        F_gen_optimizer.zero_grad()\n",
        "        F_dis_optimizer.zero_grad()\n",
        "        G_gen_optimizer.zero_grad()\n",
        "        G_dis_optimizer.zero_grad()\n",
        "        \n",
        "        #Minimize discriminator loss against ones\n",
        "        F_dis_real_output = F_dis(real_images_X)\n",
        "        F_dis_real_loss = criteriondis(F_dis_real_output.float(), ones.float())\n",
        "        F_dis_real_loss.backward()\n",
        "        F_dis_optimizer.step()\n",
        "        \n",
        "        #Minimize discriminator loss against zeros\n",
        "        F_gen_output = F_gen(real_images_X)\n",
        "        F_dis_fake_output = F_dis(F_gen_output)\n",
        "        F_dis_fake_loss = criteriondis(F_dis_fake_output.float(), zeros.float())\n",
        "        F_dis_fake_loss.backward()\n",
        "        F_dis_optimizer.step()\n",
        "        \n",
        "        #Minimize generator loss\n",
        "        F_gen_output = F_gen(real_images_X)\n",
        "        F_dis_fake_output = F_dis(F_gen_output)\n",
        "        F_gen_loss = criteriondis(F_dis_fake_output.float(), ones.float())\n",
        "        F_gen_loss.backward()\n",
        "        F_gen_optimizer.step()\n",
        "        \n",
        "        #G\n",
        "        #Minimize discriminator loss against ones\n",
        "        G_dis_real_output = G_dis(real_images_Y)\n",
        "        G_dis_real_loss = criteriondis(G_dis_real_output.float(), ones.float())\n",
        "        G_dis_real_loss.backward()\n",
        "        G_dis_optimizer.step()\n",
        "        \n",
        "        #Minimize discriminator loss against zeros\n",
        "        G_gen_output = G_gen(real_images_Y)\n",
        "        G_dis_fake_output = G_dis(G_gen_output)\n",
        "        G_dis_fake_loss = criteriondis(G_dis_fake_output.float(), zeros.float())\n",
        "        G_dis_fake_loss.backward()\n",
        "        G_dis_optimizer.step()\n",
        "        \n",
        "        #Minimize generator loss\n",
        "        G_gen_output = G_gen(real_images_Y)\n",
        "        G_dis_fake_output = G_dis(G_gen_output)        \n",
        "        G_gen_loss = criteriondis(G_dis_fake_output.float(), ones.float())\n",
        "        G_gen_loss.backward()\n",
        "        G_gen_optimizer.step()\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        F_gen_optimizer.zero_grad()\n",
        "        F_dis_optimizer.zero_grad()\n",
        "        G_gen_optimizer.zero_grad()\n",
        "        G_dis_optimizer.zero_grad()\n",
        "        \n",
        "        #Cycle consistency Loss\n",
        "        # X > Y > X\n",
        "        #F_gen_output = F_gen(real_images_X);\n",
        "        G_output = G_gen(F_gen_output);\n",
        "        F_cyclic_loss = criterion_feature(G_output, real_images_X);\n",
        "        F_gen_optimizer.step();\n",
        "        #G_gen_optimizer.step();\n",
        "        \n",
        "        # Y > X > Y\n",
        "        #G_gen_output = G_gen(real_images_Y);\n",
        "        F_output = F_gen(G_gen_output);\n",
        "        G_cyclic_loss = criterion_feature(F_output, real_images_Y)\n",
        "        G_gen_optimizer.step();\n",
        "        #F_gen_optimizer.step();\n",
        "        \n",
        "        # print statistics\n",
        "        F_running_loss_real += F_dis_real_loss.item()\n",
        "        F_running_loss_fake += F_dis_fake_loss.item()\n",
        "        F_running_loss_gen  += F_gen_loss.item()\n",
        "        G_running_loss_real += G_dis_real_loss.item()\n",
        "        G_running_loss_fake += G_dis_fake_loss.item()\n",
        "        G_running_loss_gen  += G_gen_loss.item()\n",
        "        F_running_cyclic_loss += F_cyclic_loss.item()\n",
        "        G_running_cyclic_loss += G_cyclic_loss.item()\n",
        "        \n",
        "        i += 1;\n",
        "        \n",
        "        if i % 10 == 9:    # print every 2000 mini-batches\n",
        "            print('Epoch: %d | No of images: %5d | F_real_loss: %.3f | F_fake_loss: %.3f | F_gen_loss: %.3f | F_cyclic_loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, F_running_loss_real / 10, F_running_loss_fake / 10, F_running_loss_gen / 10, F_running_cyclic_loss / 10))\n",
        "            print('Epoch: %d | No of images: %5d | G_real_loss: %.3f | G_fake_loss: %.3f | G_gen_loss: %.3f | G_cyclic_loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, G_running_loss_real / 10, G_running_loss_fake / 10, G_running_loss_gen / 10, G_running_cyclic_loss / 10))\n",
        "            F_running_loss_real = 0.0\n",
        "            F_running_loss_fake = 0.0\n",
        "            F_running_loss_gen  = 0.0\n",
        "            G_running_loss_real = 0.0\n",
        "            G_running_loss_fake = 0.0\n",
        "            G_running_loss_gen  = 0.0\n",
        "            F_running_cyclic_loss = 0.0\n",
        "            G_running_cyclic_loss = 0.0 \n",
        "#             Show output after every 2000 images\n",
        "#             temp = gen_op.cpu()\n",
        "#             imshow(torchvision.utils.make_grid(temp[0]));\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "decSy3NuoFvE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #Check for memory\n",
        "# # memory footprint support libraries/code\n",
        "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "# !pip install gputil\n",
        "# !pip install psutil\n",
        "# !pip install humanize\n",
        "# import psutil\n",
        "# import humanize\n",
        "# import os\n",
        "# import GPUtil as GPU\n",
        "# GPUs = GPU.getGPUs()\n",
        "# # XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "# gpu = GPUs[0]\n",
        "# def printm():\n",
        "#  process = psutil.Process(os.getpid())\n",
        "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "# printm()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}